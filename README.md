# 大規模言語モデル入門

<a href="https://www.amazon.co.jp/o/ASIN/4297136333/"><img src="misc/cover-small.png" width="200"></a>

「[大規模言語モデル入門](https://www.amazon.co.jp/o/ASIN/4297136333/)」（技術評論社, 2023）に掲載しているコードを公開しています。

コードはすべて Google Colaboratory で動作確認を行なっています。
コードの中で利用したデータセットや作成したモデルは[Hugging Face Hub](https://huggingface.co/llm-book)にて公開しています。

| 章 | 節 | Colab | Link |
| --- | --- | --- | --- |
| 第 1 章 はじめに | 1.1 transformers を使って自然言語処理を解いてみよう<br />1.2 transformers の基本的な使い方 | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ghmagazine/llm-book/blob/main/chapter1/1-introduction.ipynb) | [Link](https://github.com/ghmagazine/llm-book/blob/main/chapter1/1-introduction.ipynb)                    |
| 第 2 章 Transformer | 2.2 エンコーダ | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ghmagazine/llm-book/blob/main/chapter2/2-2-transformer-position-encoding.ipynb) | [Link](https://github.com/ghmagazine/llm-book/blob/main/chapter2/2-2-transformer-position-encoding.ipynb) |
| 第 3 章 大規模言語モデルの基礎 | 3.2 GPT（デコーダ）<br />3.3 BERT・RoBERTa（エンコーダ）<br />3.4 T5（エンコーダ・デコーダ）| [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ghmagazine/llm-book/blob/main/chapter3/3-zero-shot-inference.ipynb) | [Link](https://github.com/ghmagazine/llm-book/blob/main/chapter3/3-zero-shot-inference.ipynb)             |
| 第 3 章 大規模言語モデルの基礎 | 3.6 トークナイゼーション | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ghmagazine/llm-book/blob/main/chapter3/3-6-tokenization.ipynb) | [Link](https://github.com/ghmagazine/llm-book/blob/main/chapter3/3-6-tokenization.ipynb) |

## リンク

- [Hugging Face Hub](https://huggingface.co/llm-book)
- [技術評論社のページ](https://gihyo.jp/book/2023/978-4-297-13633-8)
- [Amazon.co.jp](https://www.amazon.co.jp/o/ASIN/4297136333/)
